{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import os\n",
    "import rasterio\n",
    "import shapely.geometry\n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "#%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = \"/home/ubuntu/data/TX_paired/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile_no</th>\n",
       "      <th>flooded</th>\n",
       "      <th>post-storm_full</th>\n",
       "      <th>pre-storm_full</th>\n",
       "      <th>post-storm_resized</th>\n",
       "      <th>pre-storm_resized</th>\n",
       "      <th>course_mask_full</th>\n",
       "      <th>course_mask_resized</th>\n",
       "      <th>fine_mask_filename</th>\n",
       "      <th>footprint</th>\n",
       "      <th>dry_or_wet</th>\n",
       "      <th>mask_poly</th>\n",
       "      <th>tile_transform</th>\n",
       "      <th>geometry</th>\n",
       "      <th>DBScan</th>\n",
       "      <th>DBScan_gauss</th>\n",
       "      <th>bad_image</th>\n",
       "      <th>problem</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.80323</td>\n",
       "      <td>0_post_resize_img</td>\n",
       "      <td>0_pre_resize_img</td>\n",
       "      <td>0_post_full_img</td>\n",
       "      <td>0_pre_full_img</td>\n",
       "      <td>0_mask</td>\n",
       "      <td>0_resize_mask</td>\n",
       "      <td>0_256_fine_mask</td>\n",
       "      <td>3002220.tif</td>\n",
       "      <td>wet</td>\n",
       "      <td>(POLYGON ((-95.57181511210993 29.4410615808823...</td>\n",
       "      <td>[222822.4, 0.0, 0.0, -222822.4, 21295616.0, 65...</td>\n",
       "      <td>POLYGON ((-95.56985294117646 29.44106158088235...</td>\n",
       "      <td>0_256_DBSCAN</td>\n",
       "      <td>0_256_fine_mask_blur</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8787</td>\n",
       "      <td>1_post_resize_img</td>\n",
       "      <td>1_pre_resize_img</td>\n",
       "      <td>1_post_full_img</td>\n",
       "      <td>1_pre_full_img</td>\n",
       "      <td>1_mask</td>\n",
       "      <td>1_resize_mask</td>\n",
       "      <td>1_256_fine_mask</td>\n",
       "      <td>3002220.tif</td>\n",
       "      <td>wet</td>\n",
       "      <td>POLYGON ((-95.56764981800494 29.44136752727207...</td>\n",
       "      <td>[222822.4, 0.0, 0.0, -222822.4, 21295104.0, 65...</td>\n",
       "      <td>POLYGON ((-95.56755514705883 29.44106158088235...</td>\n",
       "      <td>1_256_DBSCAN</td>\n",
       "      <td>1_256_fine_mask_blur</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tile_no  flooded    post-storm_full    pre-storm_full post-storm_resized  \\\n",
       "0       0  0.80323  0_post_resize_img  0_pre_resize_img    0_post_full_img   \n",
       "1       1   0.8787  1_post_resize_img  1_pre_resize_img    1_post_full_img   \n",
       "\n",
       "  pre-storm_resized course_mask_full course_mask_resized fine_mask_filename  \\\n",
       "0    0_pre_full_img           0_mask       0_resize_mask    0_256_fine_mask   \n",
       "1    1_pre_full_img           1_mask       1_resize_mask    1_256_fine_mask   \n",
       "\n",
       "     footprint dry_or_wet                                          mask_poly  \\\n",
       "0  3002220.tif        wet  (POLYGON ((-95.57181511210993 29.4410615808823...   \n",
       "1  3002220.tif        wet  POLYGON ((-95.56764981800494 29.44136752727207...   \n",
       "\n",
       "                                      tile_transform  \\\n",
       "0  [222822.4, 0.0, 0.0, -222822.4, 21295616.0, 65...   \n",
       "1  [222822.4, 0.0, 0.0, -222822.4, 21295104.0, 65...   \n",
       "\n",
       "                                            geometry        DBScan  \\\n",
       "0  POLYGON ((-95.56985294117646 29.44106158088235...  0_256_DBSCAN   \n",
       "1  POLYGON ((-95.56755514705883 29.44106158088235...  1_256_DBSCAN   \n",
       "\n",
       "           DBScan_gauss bad_image problem verified  \n",
       "0  0_256_fine_mask_blur      None    None     True  \n",
       "1  1_256_fine_mask_blur      None    None     True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first time use:\n",
    "#geo_df = pickle.load( open( output_dir+\"GeoDataFrame.pickled\", \"rb\" ))\n",
    "#geo_df['DBScan']=None\n",
    "\n",
    "\n",
    "#after use:\n",
    "#geo_df = pickle.load( open( output_dir+\"GeoDataFrame_fine.pickled\", \"rb\" ))\n",
    "\n",
    "\n",
    "#geo_df['DBScan_gauss']=None\n",
    "#geo_df.set_index(\"tile_no\")\n",
    "#geo_df.head(1)\n",
    "\n",
    "#after verification begins, re-doing\n",
    "geo_df = pickle.load( open( output_dir+\"GeoDataFrame_fine_turked.pickled\", \"rb\" ))\n",
    "\n",
    "geo_df.set_index(\"tile_no\")\n",
    "geo_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4022\n",
      "4022\n"
     ]
    }
   ],
   "source": [
    "#take out tiles already checked\n",
    "t = geo_df[\"verified\"] != True\n",
    "print(sum(t))\n",
    "tiles = geo_df[t].tile_no\n",
    "print(len(tiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get tile_no for those tiles with more than a little flooding\n",
    "\"\"\"t = geo_df[\"%flooded\"] > 0.00\n",
    "sum(t)\n",
    "tiles = geo_df[t].tile_no\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([383, 384, 385, ..., 4402, 4403, 4404], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('working on tile #:', 0)\n",
      "('floodwater/mud at id', 0)\n",
      "('working on tile #:', 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6ef8e82e6aba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mflat_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mclustered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#make new mask (of all labels for now)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/cluster/dbscan_.pyc\u001b[0m in \u001b[0;36mdbscan\u001b[0;34m(X, eps, min_samples, metric, metric_params, algorithm, leaf_size, p, sample_weight, n_jobs)\u001b[0m\n\u001b[1;32m    140\u001b[0m                                            \u001b[0mmetric_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                                            n_jobs=n_jobs)\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mneighbors_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;31m# This has worst case O(n^2) memory complexity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         neighborhoods = neighbors_model.radius_neighbors(X, eps,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'precomputed'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m         \"\"\"\n\u001b[0;32m--> 803\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    246\u001b[0m             self._tree = KDTree(X, self.leaf_size,\n\u001b[1;32m    247\u001b[0m                                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                                 **self.effective_metric_params_)\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'brute'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#run a subset of data at a time in case DBSCAN kills the kernel\n",
    "for tile_no in tiles.values:\n",
    "    print(\"working on tile #:\",tile_no)\n",
    "    \n",
    "    #load files\n",
    "    img_post = np.load(output_dir+'%d_post_resize_img.npy'%tile_no)\n",
    "    img_pre  = np.load(output_dir+'%d_pre_resize_img.npy'%tile_no)\n",
    "    #mask = np.load(output_dir+'%d_resize_mask.npy'%tile_no)\n",
    "    mask = np.load(output_dir+'%_256_fine_mask_blur.npy'%tile_no)\n",
    "    \n",
    "    #combine features\n",
    "    features=img_post\n",
    "    #add in subtracted image is a feature\n",
    "    #img_diff = 0.2*(img_post-img_pre)\n",
    "    #features = np.stack((img_post[:,:,0],img_post[:,:,1],img_post[:,:,2],img_diff[:,:,0],img_diff[:,:,1],img_diff[:,:,2]),axis=2)\n",
    "    #features.shape\n",
    "    \n",
    "    flat_img = np.reshape(features,(features.shape[0]**2,features.shape[2]))\n",
    "    \n",
    "    #was 2.25,1.9 too high on many images 1.7 too low\n",
    "    clustered = dbscan(flat_img,eps=1.85,min_samples=120,n_jobs=-2)\n",
    "    \n",
    "    #make new mask (of all labels for now)\n",
    "    side = int(clustered[1].shape[0]**0.5)\n",
    "    DBScan_mask = np.reshape(clustered[1],(side,side))\n",
    "    #make backup copy to save for review\n",
    "    DBScan_mask_original = copy.deepcopy(DBScan_mask)\n",
    "    \n",
    "    #order the clusters\n",
    "    c_count=Counter(DBScan_mask.flatten())\n",
    "    order = [x[0] for x in c_count.most_common() if x[0]>= 0]  #gets cluster index, AND throws out the negative-1 group\n",
    "\n",
    "    \n",
    "    #routine that checks of the masked area is too grey or green, and moves down the list of clusters it is\n",
    "    \n",
    "    ready = False\n",
    "    dry = False\n",
    "    while ready==False:\n",
    "        if len(order)==0:\n",
    "            ready = True\n",
    "            dry = True\n",
    "            c_id = None\n",
    "            break\n",
    "            #continue\n",
    "\n",
    "        c_id = order[0]\n",
    "        color_sum = (img_post*(np.expand_dims(mask==c_id,axis=2))).sum(axis=(0,1))\n",
    "        #print(color_sum)\n",
    "        #print(1.0*color_sum[1]/color_sum[0])\n",
    "\n",
    "        #reject if too grey/white/black 0.108-->0.102-->0.100\n",
    "        if color_sum.std()*1.0/color_sum.mean() < 0.100:   \n",
    "            print(\"too grey, reject cluster\",order[0],color_sum.std()*1.0/color_sum.mean())\n",
    "            order.pop(0)\n",
    "            continue\n",
    "\n",
    "        #if the most common color is too green, reject it and move to the next  1.1-->1.2-->1.18--> 1.13-->1.1\n",
    "\n",
    "        elif 1.0*color_sum[1]/color_sum[0] > 1.1:  \n",
    "            print(color_sum[1]*1.0/color_sum[0])\n",
    "            print(\"too green, reject cluster \",order[0])\n",
    "            order.pop(0)\n",
    "\n",
    "        else:ready=True\n",
    "\n",
    "    print(\"floodwater/mud at id\",c_id)\n",
    "    \n",
    "    if dry == True: fine_mask = np.zeros((side,side),dtype='int64')  #the mask data type should match\n",
    "    else: fine_mask = 1*(DBScan_mask==c_id)\n",
    "    \n",
    "    np.save(output_dir+\"%d_256_DBSCAN\"%tile_no, DBScan_mask_original)\n",
    "    np.save(output_dir+\"%d_256_fine_mask\"%tile_no, fine_mask)\n",
    "    \n",
    "    #blur mask using gaussian filter and save that too\n",
    "    DBmask_blur = ndimage.gaussian_filter(255*fine_mask, sigma=(1.5, 1.5), order=0) #was 1.3\n",
    "    threshold = 0.3\n",
    "    DBmask_blurred = DBmask_blur> 255*threshold\n",
    "    np.save(output_dir+\"%d_256_fine_mask_blur\"%tile_no, DBmask_blurred)\n",
    "    \n",
    "    #update the entry to the geopandas Dataframe with the filename\n",
    "    geo_df.DBScan[tile_no] = \"%d_256_DBSCAN\"%tile_no\n",
    "    geo_df.fine_mask_filename[tile_no] = \"%d_256_fine_mask\"%tile_no\n",
    "    #geo_df.DBScan_gauss[tile_no] = \"%d_256_fine_mask_blur\"%tile_no\n",
    "\n",
    "    #write geopandas to file too\n",
    "    geo_df.to_pickle(output_dir+\"GeoDataFrame_fine.pickled\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"        #plot for monitoring\n",
    "    fig, (ax1,ax2,ax3,ax4) = plt.subplots(1, 4, figsize=(18,6))\n",
    "    ax1.set_title(\"Post-flood Image\")\n",
    "    ax2.set_title(\"Post-flood Image w/ mask\")\n",
    "    ax3.set_title(\"Pre-flood Image\")\n",
    "    ax4.set_title(\"clusters\")\n",
    "    ax1.imshow(img_post)\n",
    "    ax2.imshow(img_post)\n",
    "    ax2.imshow(DBmask_blurred,cmap='bwr',alpha = 0.2)\n",
    "    ax3.imshow(img_pre)\n",
    "    plt.imshow(DBScan_mask)\n",
    "    plt.colorbar()\n",
    "    plt.show();\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# plotting routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,6))\n",
    "ax1.set_title(\"Flood Water Only\")\n",
    "ax2.set_title(\"Flood Water removed\")\n",
    "ax1.imshow(img_post*(np.expand_dims(DBScan_mask==c_id,axis=2)) )\n",
    "ax2.imshow(img_post*(np.expand_dims(DBScan_mask!=c_id,axis=2)));\n",
    "\n",
    "fig, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(18,6))\n",
    "ax1.set_title(\"difference image\")\n",
    "ax2.set_title(\"New Image Mask(Label)\")\n",
    "ax3.set_title(\"DigitalGlobe MDA Shapefile label\")\n",
    "ax1.imshow(img_diff)\n",
    "ax2.imshow(255.*(DBScan_mask==c_id))\n",
    "ax3.imshow(mask);\n",
    "\n",
    "fig, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(18,6))\n",
    "ax1.set_title(\"Post-flood Image\")\n",
    "ax2.set_title(\"DBSCAN Clusters\")\n",
    "ax3.set_title(\"Pre-flood Image\")\n",
    "ax1.imshow(img_post)\n",
    "ax2.imshow(DBScan_mask)\n",
    "ax3.imshow(img_pre);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2,ax3,ax4) = plt.subplots(1, 4, figsize=(18,6))\n",
    "ax1.set_title(\"Post-flood Image\")\n",
    "ax2.set_title(\"Post-flood Image w/ mask\")\n",
    "ax3.set_title(\"Pre-flood Image\")\n",
    "ax4.set_title(\"clusters\")\n",
    "ax1.imshow(img_post)\n",
    "ax2.imshow(img_post)\n",
    "ax2.imshow(1-(DBScan_mask==c_id),cmap='bwr',alpha = 0.2)\n",
    "ax3.imshow(img_pre)\n",
    "plt.imshow(DBScan_mask)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
